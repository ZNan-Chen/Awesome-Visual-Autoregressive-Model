# Awesome-Visual-Autoregressive-Model
ðŸŒŸThis repository is still being updated, please stay tuned.

ðŸ‘‰If you find mistakes or overlooked papers, please open issues or pull requests.

## Content:
- [Image Generation](#Image-Generation)
- [Video Generation](#Video-Generation)
- [Multimodal Generation](#Multimodal-Generation)
- [Understanding or Optimization](#Understanding-or-Optimization)
- [Others](#Others)

--------------------------------------------------------------------------------------

## Image Generation
| **Title** | **Venue** |  **Links** |
|:--------|:--------:|:--------:|
| EditAR: Unified Conditional Generation with Autoregressive Models | Arxiv2025 | [Paper](https://arxiv.org/pdf/2501.04699)\|[Code](https://github.com/JitengMu/EditAR)
| Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction | NeurIPS2024 | [Paper](https://arxiv.org/pdf/2404.02905)\|[Code](https://github.com/FoundationVision/VAR)
| Infinityâˆž: Scaling Bitwise AutoRegressive Modeling for High-Resolution Image Synthesis | Arxiv2024 | [Paper](https://arxiv.org/pdf/2412.04431)\|[Code](https://github.com/FoundationVision/Infinity)
| Autoregressive Model Beats Diffusion: Llama for Scalable Image Generation | Arxiv2024 | [Paper](https://arxiv.org/pdf/2406.06525)\|[Code](https://github.com/FoundationVision/LlamaGen)
| STAR: Scale-wise Text-to-image generation via Auto-Regressive representations | Arxiv2024 | [Paper](https://github.com/krennic999/STAR)\|[Code](https://github.com/krennic999/STAR)
| VAR-CLIP: Text-to-Image Generator with Visual Auto-Regressive Modeling | Arxiv2024 | [Paper](https://arxiv.org/pdf/2408.01181)\|[Code](https://github.com/daixiangzi/VAR-CLIP)
| ControlVAR: Exploring Controllable Visual Autoregressive Modeling | Arixv2024 | [Paper](https://arxiv.org/pdf/2406.09750)\|[Code](https://github.com/lxa9867/ControlVAR)
| ImageFolderðŸš€: Autoregressive Image Generation with Folded Tokens | Arxiv2024 | [Paper](https://arxiv.org/pdf/2412.01762)\|[Code](https://github.com/lxa9867/ImageFolder)
| HART: Efficient Visual Generation with Hybrid Autoregressive Transformer | Arxiv2024 | [Paper](https://arxiv.org/pdf/2410.10812)\|[Code](https://github.com/mit-han-lab/hart?tab=readme-ov-file)
| M-VAR: Decoupled Scale-wise Autoregressive Modeling for High-Quality Image Generation | Arxiv2024 | [Paper](https://arxiv.org/pdf/2411.10433)\|[Code](https://github.com/OliverRensu/MVAR?tab=readme-ov-file)

## Video Generation
| **Title** | **Venue** |  **Links** |
|:--------|:--------:|:--------:|
| GameFactory: Creating New Games with Generative Interactive Videos | Arxiv2025 | [Paper](https://arxiv.org/pdf/2501.08325)\|[Code](https://github.com/KwaiVGI/GameFactory)
| StarGen: A Spatiotemporal Autoregression Framework with Video Diffusion Model for Scalable and Controllable Scene Generation | Arxiv2025 | [Paper](https://arxiv.org/pdf/2501.05763)\|[Code](https://github.com/zju3dv/StarGen)
| An Empirical Study of Autoregressive Pre-training from Videos | Arxiv2025 | [Paper](https://arxiv.org/pdf/2501.01722)\|Code
| AR4D: Autoregressive 4D Generation from Monocular Videos | Arxiv2025 | [Paper](https://arxiv.org/pdf/2501.01722)\|Code
| Video-LaVIT: Unified Video-Language Pre-training with Decoupled Visual-Motional Tokenization | ICML2024 | [Paper](https://arxiv.org/pdf/2402.03161)\|[Code](https://github.com/jy0205/LaVIT)
| ARTâ€¢V: Auto-Regressive Text-to-Video Generation with Diffusion Models | CVPRW2024 | [Paper](https://arxiv.org/pdf/2311.18834)\|[Code](https://github.com/WarranWeng/ART.V)
| Autoregressive Video Generation without Vector Quantization | Arxiv2024 | [Paper](https://arxiv.org/pdf/2412.14169)\|[Code](https://github.com/baaivision/NOVA)
| MarDini: Masked Auto-Regressive Diffusion for Video Generation at Scale | Arxiv2024 | [Paper](https://arxiv.org/pdf/2410.20280)\|Code
| Loong: Generating Minute-level Long Videos with Autoregressive Language Models  | Arxiv2024 | [Paper](https://arxiv.org/pdf/2410.02757)\|Code
| ARLON: Boosting Diffusion Transformers with Autoregressive Models for Long Video Generation | Arxiv2024 | [Paper](https://arxiv.org/pdf/2410.20502)\|Code
| DiCoDe: Diffusion-Compressed Deep Tokens for Autoregressive Video Generation with Language Models | Arxiv2024 | [Paper](https://arxiv.org/pdf/2412.04446)\|Code

## 3D Generation
| **Title** | **Venue** |  **Links** |
|:--------|:--------:|:--------:|
| General Point Model Pretraining with Autoencoding and Autoregressive | CVPR2024 | [Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Li_General_Point_Model_Pretraining_with_Autoencoding_and_Autoregressive_CVPR_2024_paper.pdf)\|[Code](https://github.com/gentlefress/GPM)
| Bidirectional Autoregressive Diffusion Model for Dance Generation | CVPR2024 | [Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Zhang_Bidirectional_Autoregessive_Diffusion_Model_for_Dance_Generation_CVPR_2024_paper.pdf)\|[Code](https://github.com/czzhang179/BADM)
| SceneScript: Reconstructing Scenes With An Autoregressive Structured Language Model | ECCV2024 | [Paper](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/07833.pdf)\|[Code](https://github.com/facebookresearch/scenescript)
| BAMM: Bidirectional Autoregressive Motion Model | ECCV2024 | [Paper](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/02316.pdf)\|[Code](https://github.com/exitudio/BAMM/)
| SAR3D: Autoregressive 3D Object Generation and Understanding via Multi-scale 3D VQVAE | Arxiv2024 | [Paper](https://arxiv.org/pdf/2411.16856)\|[Code](https://github.com/cyw-3d/SAR3D)
| 3D representation in 512-Byte: Variational tokenizer is the key for autoregressive 3D generation | Arxiv2024 | [Paper](https://arxiv.org/pdf/2412.02202)\|[Code](https://github.com/sparse-mvs-2/VAT)

## Multimodal Generation
| **Title** | **Venue** |  **Links** |
|:--------|:--------:|:--------:|
| Mirasol3B: A Multimodal Autoregressive model for time-aligned and contextual modalities | CVPR2024 | [Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Piergiovanni_Mirasol3B_A_Multimodal_Autoregressive_Model_for_Time-Aligned_and_Contextual_Modalities_CVPR_2024_paper.pdf)\|Code
| Unified-IO 2: Scaling Autoregressive Multimodal Models with Vision, Language, Audio, and Action | CVPR2024 | [Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Lu_Unified-IO_2_Scaling_Autoregressive_Multimodal_Models_with_Vision_Language_Audio_CVPR_2024_paper.pdf)\|Code
| VideoPoet: A Large Language Model for Zero-Shot Video Generation | ICML2024 | [Paper](https://sites.research.google/videopoet/)\|Code
| VITRON: A Unified Pixel-level Vision LLM for Understanding, Generating, Segmenting, Editing | NeurIPS2024 | [Paper](https://haofei.vip/downloads/papers/Skywork_Vitron_2024.pdf)\|[Code](https://github.com/SkyworkAI/Vitron?tab=readme-ov-file)
| OmniTokenizer: A Joint Image-Video Tokenizer for Visual Generation | NeurIPS2024 | [Paper](https://arxiv.org/pdf/2406.09399)\|[Code](https://github.com/FoundationVision/OmniTokenizer?tab=readme-ov-file)
| DrivingGPT: Unifying Driving World Modeling and Planning with Multi-modal Autoregressive Transformers | Arxiv2024 | [Paper](https://arxiv.org/pdf/2412.18607)\|Code
| Emu3: Next-Token Prediction is All You Need | Arxiv2024 | [Paper](https://arxiv.org/pdf/2409.18869)\|[Code](https://github.com/baaivision/Emu3)

## Understanding or Optimization
| **Title** | **Venue** |  **Links** |
|:--------|:--------:|:--------:|
| Next Patch Prediction for Autoregressive Visual Generation | Arxiv2025 | [Paper](https://arxiv.org/pdf/2412.15321)\|[Code](https://github.com/PKU-YuanGroup/Next-Patch-Prediction)
| Language Model Beats Diffusion -- Tokenizer is Key to Visual Generation | ICLR2024 | [Paper](https://arxiv.org/pdf/2310.05737)\|Code
| E-CAR: Efficient Continuous Autoregressive Image Generation via Multistage Modeling | Arxiv2024 | [Paper](https://arxiv.org/pdf/2411.17178)\|Code
| LiteVAR: Compressing Visual Autoregressive Modelling with Efficient Attention and Quantization | Arxiv2024 | [Paper](https://arxiv.org/pdf/2412.14170)\|Code
| CoDe: Collaborative Decoding Makes Visual Auto-Regressive Modeling Efficient | Arxiv2024 | [Paper](https://arxiv.org/pdf/2411.17787)\|[Code](https://github.com/czg1225/CoDe)
| XQ-GANðŸš€: An Open-source Image Tokenization Framework for Autoregressive Generation | Arxiv2024 | [Paper](https://arxiv.org/pdf/2412.01762)\|[Code](https://github.com/lxa9867/ImageFolder?tab=readme-ov-file)
| TokenFlowðŸš€: Unified Image Tokenizer for Multimodal Understanding and Generation | Arxiv2024 | [Paper](https://arxiv.org/pdf/2412.03069)\|[Code](https://github.com/ByteFlow-AI/TokenFlow?tab=readme-ov-file)
| Switti: Designing Scale-Wise Transformers for Text-to-Image Synthesis | Arxiv2024 | [Paper](https://arxiv.org/pdf/2412.01819)\|[Code](https://github.com/yandex-research/switti?tab=readme-ov-file)
| FlowAR: Scale-wise Autoregressive Image Generation Meets Flow Matching | Arxiv2024 | [Paper](https://arxiv.org/pdf/2412.15205)\|[Code](https://github.com/OliverRensu/FlowAR)
| Distilled Decoding 1: One-step Sampling of Image Auto-regressive Models with Flow Matching | Arxiv2024 | [Paper](https://arxiv.org/abs/2412.17153)\|[Code](https://github.com/imagination-research/distilled-decoding)
| Next Token Prediction Towards Multimodal Intelligence | Arxiv2024 | [Paper](https://arxiv.org/abs/2412.18619)\|[Code](https://github.com/LMM101/Awesome-Multimodal-Next-Token-Prediction)
| Parallelized Autoregressive Visual Generation | Arxiv2024 | [Paper](https://arxiv.org/pdf/2412.15119)\|[Code](https://github.com/Epiphqny/PAR)

## Others:
| **Title** | **Venue** |  **Links** |
|:--------|:--------:|:--------:|
| DeTrack: In-model Latent Denoising Learning for Visual Object Tracking | Arxiv2025 | [Paper](https://arxiv.org/html/2501.02467v1)\|Code
| Less is More: Token Context-aware Learning for Object Tracking | AAAI2025 | [Paper](https://arxiv.org/pdf/2501.00758)\|[Code](https://github.com/XuChenLong/LMTrack)
| DiffusionPoser: Real-time Human Motion Reconstruction From Arbitrary Sparse Sensors Using Autoregressive Diffusion | CVPR2024 | [Paper](https://openaccess.thecvf.com/content/CVPR2024/papers/Van_Wouwe_DiffusionPoser_Real-time_Human_Motion_Reconstruction_From_Arbitrary_Sparse_Sensors_Using_CVPR_2024_paper.pdf)\|Code
| CARP: Visuomotor Policy Learning via Coarse-to-Fine Autoregressive Prediction | Arxiv2024 | [Paper](https://arxiv.org/pdf/2412.06782)\|Code
| Varformer: Adapting VARâ€™s Generative Prior for Image Restoration | Arxiv2024 | [Paper](https://arxiv.org/pdf/2412.21063)\|[Code](https://github.com/siywang541/Varformer)
| Scalable Autoregressive Monocular Depth Estimation | Arxiv2024 | [Paper](https://arxiv.org/pdf/2411.11361)\|Code

